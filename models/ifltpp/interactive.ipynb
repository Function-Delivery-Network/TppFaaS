{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dpp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from time import process_time\n",
    "#torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_batched_high_load_n_400/20210610_23:14_fanout_large_fetched_397_n_400_l_0.01_u_0.01_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_00:04_parallel_large_fetched_390_n_400_l_0.01_u_0.01_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_00:53_tree_large_fetched_399_n_400_l_0.01_u_0.01_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_01:43_fanout_large_fetched_391_n_400_l_0.01_u_0.01_b_50_w_120_rand',\n",
       " 'final_batched_high_load_n_400/20210611_02:33_parallel_large_fetched_383_n_400_l_0.01_u_0.01_b_50_w_120_rand',\n",
       " 'final_batched_high_load_n_400/20210611_03:23_tree_large_fetched_398_n_400_l_0.01_u_0.01_b_50_w_120_rand',\n",
       " 'final_batched_high_load_n_400/20210611_04:13_fanout_small_fetched_384_n_400_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_07:23_fanout_small_fetched_394_n_400_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_batched_high_load_n_400/20210611_11:32_parallel_small_fetched_397_n_400_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_12:23_tree_small_fetched_399_n_400_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_12:49_parallel_small_fetched_398_n_400_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_batched_high_load_n_400/20210611_13:40_tree_small_fetched_394_n_400_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_batched_high_load_n_400/20210611_16:55_sequence_fetched_500_n_500_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_batched_high_load_n_400/20210611_17:16_sequence_fetched_500_n_500_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210610_23:14_fanout_large_fetched_397_n_400_l_0.01_u_0.01_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_00:04_parallel_large_fetched_390_n_400_l_0.01_u_0.01_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_00:53_tree_large_fetched_399_n_400_l_0.01_u_0.01_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_01:43_fanout_large_fetched_391_n_400_l_0.01_u_0.01_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210611_02:33_parallel_large_fetched_383_n_400_l_0.01_u_0.01_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210611_03:23_tree_large_fetched_398_n_400_l_0.01_u_0.01_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210611_04:13_fanout_small_fetched_384_n_400_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_07:23_fanout_small_fetched_394_n_400_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210611_11:32_parallel_small_fetched_397_n_400_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_12:23_tree_small_fetched_399_n_400_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_12:49_parallel_small_fetched_398_n_400_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210611_13:40_tree_small_fetched_394_n_400_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_high_load_n_1000/injected_20210611_16:55_sequence_fetched_500_n_500_l_0.0001_u_0.0001_b_50_w_120',\n",
       " 'final_high_load_n_1000/injected_20210611_17:16_sequence_fetched_500_n_500_l_0.0001_u_0.0001_b_50_w_120_rand',\n",
       " 'final_low_load_n_1000/20210604_23:26_fanout_large_fetched_1000_n_1000_l_0.9_u_1.4',\n",
       " 'final_low_load_n_1000/20210604_23:49_parallel_large_fetched_1000_n_1000_l_0.9_u_1.4',\n",
       " 'final_low_load_n_1000/20210605_00:21_tree_large_fetched_999_n_1000_l_0.9_u_1.4',\n",
       " 'final_low_load_n_1000/20210605_00:45_fanout_large_fetched_1000_n_1000_l_0.9_u_1.4_rand',\n",
       " 'final_low_load_n_1000/20210605_01:08_parallel_large_fetched_1000_n_1000_l_0.9_u_1.4_rand',\n",
       " 'final_low_load_n_1000/20210605_01:32_tree_large_fetched_1000_n_1000_l_0.9_u_1.4_rand',\n",
       " 'final_low_load_n_1000/20210605_01:44_fanout_small_fetched_1000_n_1000_l_0.3_u_0.6',\n",
       " 'final_low_load_n_1000/20210605_01:56_parallel_small_fetched_1000_n_1000_l_0.3_u_0.6',\n",
       " 'final_low_load_n_1000/20210605_02:08_sequence_fetched_1000_n_1000_l_0.3_u_0.6',\n",
       " 'final_low_load_n_1000/20210605_02:19_tree_small_fetched_1000_n_1000_l_0.3_u_0.6',\n",
       " 'final_low_load_n_1000/20210605_02:31_fanout_small_fetched_1000_n_1000_l_0.3_u_0.6_rand',\n",
       " 'final_low_load_n_1000/20210605_02:43_parallel_small_fetched_1000_n_1000_l_0.3_u_0.6_rand',\n",
       " 'final_low_load_n_1000/20210605_02:55_sequence_fetched_1000_n_1000_l_0.3_u_0.6_rand',\n",
       " 'final_low_load_n_1000/20210605_03:07_tree_small_fetched_1000_n_1000_l_0.3_u_0.6_rand']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpp.data.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "dataset_name = \"final_low_load_n_1000/20210605_02:55_sequence_fetched_1000_n_1000_l_0.3_u_0.6_rand\"  # run dpp.data.list_datasets() to see the list of available datasets\n",
    "\n",
    "# Model config\n",
    "context_size = 64                 # Size of the RNN hidden vector\n",
    "mark_embedding_size = 32          # Size of the mark embedding (used as RNN input)\n",
    "coldstart_feature = True          # Model feature indicating if the last invocation was a cold start\n",
    "coldstart_embedding_size = 32     # Size of the cold start feature embedding (used as RNN input)\n",
    "num_mix_components = 16           # Number of components for a mixture model\n",
    "rnn_type = \"GRU\"                  # What RNN to use as an encoder {\"RNN\", \"GRU\", \"LSTM\"}\n",
    "mae_loss = False                  # Evaluate the predicted time for the next invocation with the mean absolute error.\n",
    "                                  # Therefore, the model predicts \\tau directly instead of the PDF f^*(\\tau) (see 'TruncNorm' in the paper)\n",
    "\n",
    "# Training config\n",
    "batch_size = 64        # Number of sequences in a batch\n",
    "regularization = 1e-5  # L2 regularization parameter\n",
    "learning_rate = 1e-3   # Learning rate for Adam optimizer\n",
    "max_epochs = 200       # For how many epochs to train\n",
    "display_step = 5       # Display training statistics after every display_step\n",
    "patience = 20          # After how many consecutive epochs without improvement of val loss to stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dataset = dpp.data.load_dataset(dataset_name)\n",
    "d_train, d_val, d_test = dataset.train_val_test_split(seed=seed)\n",
    "\n",
    "dl_train = d_train.get_dataloader(batch_size=batch_size, shuffle=True)\n",
    "dl_val = d_val.get_dataloader(batch_size=batch_size, shuffle=False)\n",
    "dl_test = d_test.get_dataloader(batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "print('Building model...')\n",
    "mean_log_inter_time, std_log_inter_time = d_train.get_inter_time_statistics()\n",
    "\n",
    "model = dpp.models.LogNormMix(\n",
    "    num_marks=d_train.num_marks,\n",
    "    mean_log_inter_time=mean_log_inter_time,\n",
    "    std_log_inter_time=std_log_inter_time,\n",
    "    context_size=context_size,\n",
    "    mark_embedding_size=mark_embedding_size,\n",
    "    rnn_type=rnn_type,\n",
    "    num_mix_components=num_mix_components,\n",
    "    coldstart_feature=coldstart_feature,\n",
    "    coldstart_embedding_size=coldstart_embedding_size\n",
    ")\n",
    "opt = torch.optim.Adam(model.parameters(), weight_decay=regularization, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def inter_time_errors(batch):\n",
    "    predicted_inter_times, _ = model.predict(batch)\n",
    "    errors = predicted_inter_times - batch.inter_times\n",
    "    #indices = torch.nonzero(batch.mask, as_tuple=True)\n",
    "    #return errors[indices]\n",
    "    index = torch.nonzero(batch.mask.sum(dim=0), as_tuple=True)[0]  # Only works if all sequences have the same length.\n",
    "    return errors.index_select(dim=1, index=index)\n",
    "\n",
    "def correct_predicted_marks(batch):\n",
    "    _, predicted_marks = model.predict(batch)\n",
    "    correct_predictions = predicted_marks == batch.marks\n",
    "    index = torch.nonzero(batch.mask.sum(dim=0), as_tuple=True)[0]  # Only works if all sequences have the same length.\n",
    "    return correct_predictions.index_select(dim=1, index=index)\n",
    "\n",
    "def aggregate_loss_over_dataloader(dl, mae_loss):\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            if mae_loss:\n",
    "                total_loss += (inter_time_errors(batch).abs().sum() - model.mark_log_prob(batch).sum()).item()\n",
    "            else:\n",
    "                total_loss += -model.log_prob(batch).sum().item()\n",
    "            total_count += batch.mask.sum().item()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def aggregate_mark_nll_over_dataloader(dl):\n",
    "    total_loss = 0.0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            total_loss += -model.mark_log_prob(batch).sum().item()\n",
    "            total_count += batch.mask.sum().item()\n",
    "    return total_loss / total_count\n",
    "\n",
    "def aggregate_mae_over_dataloader(dl):\n",
    "    total_mae = 0.0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            total_mae += inter_time_errors(batch).abs().sum().item()\n",
    "            total_count += batch.mask.sum().item()\n",
    "    return total_mae / total_count\n",
    "\n",
    "def aggregate_accuracy_over_dataloader(dl):\n",
    "    total_correct_predictions = 0.0\n",
    "    total_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            total_correct_predictions += correct_predicted_marks(batch).sum().item()\n",
    "            total_count += batch.mask.sum().item()\n",
    "    return total_correct_predictions / total_count\n",
    "\n",
    "def inter_time_errors_over_dataloader(dl):\n",
    "    result = torch.Tensor()\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            result = torch.cat([result, inter_time_errors(batch)], dim=0)\n",
    "    return result\n",
    "\n",
    "def correct_predicted_marks_over_dataloader(dl):\n",
    "    result = torch.Tensor()\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            result = torch.cat([result, correct_predicted_marks(batch)], dim=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch    0 of  200: loss_train_last_batch = 105.460, loss_val = 10.466, mark_nll_val = 2.023, mae_val = 388.785, acc_val = 0.700\n",
      "Epoch    5 of  200: loss_train_last_batch = 71.396, loss_val = 7.166, mark_nll_val = 1.155, mae_val = 388.933, acc_val = 1.000\n",
      "Epoch   10 of  200: loss_train_last_batch = 61.669, loss_val = 6.168, mark_nll_val = 0.519, mae_val = 388.908, acc_val = 1.000\n",
      "Epoch   15 of  200: loss_train_last_batch = 56.939, loss_val = 5.744, mark_nll_val = 0.193, mae_val = 388.905, acc_val = 1.000\n",
      "Epoch   20 of  200: loss_train_last_batch = 55.150, loss_val = 5.543, mark_nll_val = 0.095, mae_val = 388.904, acc_val = 1.000\n",
      "Epoch   25 of  200: loss_train_last_batch = 54.806, loss_val = 5.518, mark_nll_val = 0.057, mae_val = 388.902, acc_val = 1.000\n",
      "Epoch   30 of  200: loss_train_last_batch = 54.290, loss_val = 5.484, mark_nll_val = 0.039, mae_val = 388.902, acc_val = 1.000\n",
      "Epoch   35 of  200: loss_train_last_batch = 55.294, loss_val = 5.506, mark_nll_val = 0.029, mae_val = 388.901, acc_val = 1.000\n",
      "Epoch   40 of  200: loss_train_last_batch = 54.430, loss_val = 5.504, mark_nll_val = 0.022, mae_val = 388.900, acc_val = 1.000\n",
      "Epoch   45 of  200: loss_train_last_batch = 53.926, loss_val = 5.454, mark_nll_val = 0.018, mae_val = 388.900, acc_val = 1.000\n",
      "Epoch   50 of  200: loss_train_last_batch = 54.353, loss_val = 5.424, mark_nll_val = 0.015, mae_val = 388.900, acc_val = 1.000\n",
      "Epoch   55 of  200: loss_train_last_batch = 55.458, loss_val = 5.424, mark_nll_val = 0.012, mae_val = 388.899, acc_val = 1.000\n",
      "Epoch   60 of  200: loss_train_last_batch = 55.002, loss_val = 5.431, mark_nll_val = 0.011, mae_val = 388.899, acc_val = 1.000\n",
      "Epoch   65 of  200: loss_train_last_batch = 54.224, loss_val = 5.440, mark_nll_val = 0.009, mae_val = 388.899, acc_val = 1.000\n",
      "Epoch   70 of  200: loss_train_last_batch = 54.169, loss_val = 5.444, mark_nll_val = 0.008, mae_val = 388.898, acc_val = 1.000\n",
      "Breaking due to early stopping at epoch 75\n",
      "Trained process time: 25.819s\n",
      "Trained epochs: 76\n"
     ]
    }
   ],
   "source": [
    "# Traning\n",
    "print('Starting training...')\n",
    "\n",
    "impatient = 0\n",
    "best_loss = np.inf\n",
    "best_model = deepcopy(model.state_dict())\n",
    "start_processtime = process_time()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    for batch in dl_train:\n",
    "        opt.zero_grad()\n",
    "        loss = 0.0\n",
    "        if mae_loss:\n",
    "            loss = inter_time_errors(batch).abs().mean() - model.mark_log_prob(batch).mean()\n",
    "        else:\n",
    "            loss = -model.log_prob(batch).mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_val = aggregate_loss_over_dataloader(dl_val, mae_loss)\n",
    "        mark_nll_val = aggregate_mark_nll_over_dataloader(dl_val)\n",
    "        mae_val = aggregate_mae_over_dataloader(dl_val)\n",
    "        acc_val = aggregate_accuracy_over_dataloader(dl_val)\n",
    "\n",
    "    if (best_loss - loss_val) < 1e-4:\n",
    "        impatient += 1\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "    else:\n",
    "        best_loss = loss_val\n",
    "        best_model = deepcopy(model.state_dict())\n",
    "        impatient = 0\n",
    "\n",
    "    if impatient >= patience:\n",
    "        print(f'Breaking due to early stopping at epoch {epoch}')\n",
    "        break\n",
    "\n",
    "    if epoch % display_step == 0:\n",
    "        print(f\"Epoch {epoch:4d} of {max_epochs:4d}: loss_train_last_batch = {loss.item():.3f}, loss_val = {loss_val:.3f}, mark_nll_val = {mark_nll_val:.3f}, mae_val = {mae_val:.3f}, acc_val = {acc_val:.3f}\")\n",
    "\n",
    "trained_processtime = process_time() - start_processtime\n",
    "print(f\"Trained process time: {trained_processtime:.3f}s\\n\"\n",
    "      f\"Trained epochs: {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss (= NLL_time + NLL_mark):\n",
      "- Train: 5.446\n",
      "- Val:   5.424\n",
      "- Test:  5.428\n",
      "Mark negative log-likelihood (NLL_mark):\n",
      "- Train: 0.013\n",
      "- Val:   0.012\n",
      "- Test:  0.012\n",
      "Accuracy:\n",
      "- Train: 1.000\n",
      "- Val:   1.000\n",
      "- Test:  1.000\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "# Evaluation via total loss (= NLL_time + NLL_mark, if mae_loss=False, = MAE_time + NLL_mark, else)\n",
    "with torch.no_grad():\n",
    "    final_loss_train = aggregate_loss_over_dataloader(dl_train, mae_loss)\n",
    "    final_loss_val = aggregate_loss_over_dataloader(dl_val, mae_loss)\n",
    "    final_loss_test = aggregate_loss_over_dataloader(dl_test, mae_loss)\n",
    "s = \"NLL_time + NLL_mark\"\n",
    "if mae_loss:\n",
    "    s = \"MAE_time + NLL_mark\"\n",
    "print(f'Total loss (= {s}):\\n'\n",
    "    f'- Train: {final_loss_train:.3f}\\n'\n",
    "    f'- Val:   {final_loss_val:.3f}\\n'\n",
    "    f'- Test:  {final_loss_test:.3f}')\n",
    "# Evaluation via mark negative log-likelihood\n",
    "with torch.no_grad():\n",
    "    final_mark_nll_train = aggregate_mark_nll_over_dataloader(dl_train)\n",
    "    final_mark_nll_val = aggregate_mark_nll_over_dataloader(dl_val)\n",
    "    final_mark_nll_test = aggregate_mark_nll_over_dataloader(dl_test)\n",
    "print(f'Mark negative log-likelihood (NLL_mark):\\n'\n",
    "    f'- Train: {final_mark_nll_train:.3f}\\n'\n",
    "    f'- Val:   {final_mark_nll_val:.3f}\\n'\n",
    "    f'- Test:  {final_mark_nll_test:.3f}')\n",
    "# Evaluation via accuracy\n",
    "with torch.no_grad():\n",
    "    final_acc_train = aggregate_accuracy_over_dataloader(dl_train)\n",
    "    final_acc_val = aggregate_accuracy_over_dataloader(dl_val)\n",
    "    final_acc_test = aggregate_accuracy_over_dataloader(dl_test)\n",
    "print(f'Accuracy:\\n'\n",
    "    f'- Train: {final_acc_train:.3f}\\n'\n",
    "    f'- Val:   {final_acc_val:.3f}\\n'\n",
    "    f'- Test:  {final_acc_test:.3f}')\n",
    "if mae_loss:\n",
    "    # Evaluation via mean absolute error\n",
    "    with torch.no_grad():\n",
    "        final_mae_train = aggregate_mae_over_dataloader(dl_train)\n",
    "        final_mae_val = aggregate_mae_over_dataloader(dl_val)\n",
    "        final_mae_test = aggregate_mae_over_dataloader(dl_test)\n",
    "    print(f'Mean absolute error (MAE):\\n'\n",
    "        f'- Train: {final_mae_train:.3f}\\n'\n",
    "        f'- Val:   {final_mae_val:.3f}\\n'\n",
    "        f'- Test:  {final_mae_test:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/tppfaas/lib/python3.9/site-packages/numpy/lib/histograms.py:906: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation of differences between predicted and true inter-time\n",
    "model.load_state_dict(best_model)\n",
    "model.eval() \n",
    "\n",
    "plt.hist(inter_time_errors_over_dataloader(dl_test).numpy(), bins=100, label=\"test\", range=(-80, 80), density=True)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Difference to true inter-time (ms)\")\n",
    "plt.title(\"Differences between Predicted and True Inter-Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eab8d6e6b2d802a92b213253e67d01208d34a5ba75b93b41b5d52fbeb698e3"
  },
  "kernelspec": {
   "display_name": "ifltpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "f977599a756708fbfdd0fdf6f342412f314e8fc379cda59ccfbf9fdfe5b18870"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
